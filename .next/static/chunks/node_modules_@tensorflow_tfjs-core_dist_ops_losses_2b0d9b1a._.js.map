{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 7, "column": 0}, "map": {"version":3,"file":"compute_weighted_loss.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-core/dist/ops/losses/compute_weighted_loss.js/__/__/__/__/__/__/__/tfjs-core/src/ops/losses/compute_weighted_loss.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\n\nimport {cast} from '../cast';\nimport {div} from '../div';\nimport {Reduction} from '../loss_ops_utils';\nimport {mean} from '../mean';\nimport {mul} from '../mul';\nimport {notEqual} from '../not_equal';\nimport {ones} from '../ones';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {sum} from '../sum';\n\n/**\n * Computes the weighted loss between two tensors.\n *\n * @param losses Tensor of shape `[batch_size, d1, ..., dN]`.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `losses`, and must be broadcastable to `losses` (i.e., all\n *    dimensions must be either `1`, or the same as the corresponding\n *    `losses` dimension).\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction computeWeightedLoss_<T extends Tensor, O extends Tensor>(\n    losses: T|TensorLike, weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $losses = convertToTensor(losses, 'losses', 'computeWeightedLoss');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'computeWeightedLoss');\n  }\n\n  const weightedLoss = ($weights == null) ? $losses : mul($losses, $weights);\n\n  if (reduction === Reduction.NONE) {\n    return weightedLoss as O;\n  }\n  if (reduction === Reduction.SUM) {\n    return sum(weightedLoss);\n  }\n  if (reduction === Reduction.MEAN) {\n    if ($weights == null) {\n      return mean(weightedLoss);\n    } else {\n      const broadcastFactor = $losses.size / $weights.size;\n      const result = div(sum(weightedLoss), sum($weights));\n      return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) :\n                                   result as O;\n    }\n  }\n  if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    if ($weights == null) {\n      return div(sum(weightedLoss), scalar($losses.size));\n    } else {\n      const broadcastedWeights = mul($weights, ones($losses.shape));\n\n      const numNonZeros =\n          cast(sum(notEqual(broadcastedWeights, scalar(0))), 'float32');\n      return div(sum(weightedLoss), numNonZeros);\n    }\n  }\n\n  throw Error(`Unknown reduction: ${reduction}`);\n}\nexport const computeWeightedLoss = /* @__PURE__ */ op({computeWeightedLoss_});\n"],"names":[],"mappings":";;;AAiBA,OAAO,EAAC,eAAe,EAAC,MAAM,uBAAuB,CAAC;AAGtD,OAAO,EAAC,IAAI,EAAC,MAAM,SAAS,CAAC;AAC7B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAC5C,OAAO,EAAC,IAAI,EAAC,MAAM,SAAS,CAAC;AAC7B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,QAAQ,EAAC,MAAM,cAAc,CAAC;AACtC,OAAO,EAAC,IAAI,EAAC,MAAM,SAAS,CAAC;AAC7B,OAAO,EAAC,EAAE,EAAC,MAAM,cAAc,CAAC;AAChC,OAAO,EAAC,MAAM,EAAC,MAAM,WAAW,CAAC;AACjC,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;;;;;;;;;;;;AAE3B;;;;;;;;;;GAUG,CACH,SAAS,oBAAoB,CACzB,MAAoB,EAAE,OAA2B,EACjD,SAAS,oLAAG,YAAS,CAAC,sBAAsB;IAC9C,MAAM,OAAO,kLAAG,kBAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,qBAAqB,CAAC,CAAC;IACzE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,OAAG,6LAAA,AAAe,EAAC,OAAO,EAAE,SAAS,EAAE,qBAAqB,CAAC,CAAC;KACvE;IAED,MAAM,YAAY,GAAG,AAAC,QAAQ,IAAI,IAAI,CAAC,CAAC,CAAC,AAAC,OAAO,CAAC,CAAC,2KAAC,MAAA,AAAG,EAAC,OAAO,EAAE,QAAQ,CAAC,CAAC;IAE3E,IAAI,SAAS,sLAAK,YAAS,CAAC,IAAI,EAAE;QAChC,OAAO,YAAiB,CAAC;KAC1B;IACD,IAAI,SAAS,sLAAK,YAAS,CAAC,GAAG,EAAE;QAC/B,OAAO,gLAAA,AAAG,EAAC,YAAY,CAAC,CAAC;KAC1B;IACD,IAAI,SAAS,sLAAK,YAAS,CAAC,IAAI,EAAE;QAChC,IAAI,QAAQ,IAAI,IAAI,EAAE;YACpB,QAAO,iLAAA,AAAI,EAAC,YAAY,CAAC,CAAC;SAC3B,MAAM;YACL,MAAM,eAAe,GAAG,OAAO,CAAC,IAAI,GAAG,QAAQ,CAAC,IAAI,CAAC;YACrD,MAAM,MAAM,GAAG,gLAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,YAAY,CAAC,EAAE,gLAAA,AAAG,EAAC,QAAQ,CAAC,CAAC,CAAC;YACrD,OAAO,eAAe,GAAG,CAAC,CAAC,CAAC,2KAAC,MAAA,AAAG,EAAC,MAAM,EAAE,sLAAA,AAAM,EAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CACtC,MAAW,CAAC;SAC1C;KACF;IACD,IAAI,SAAS,sLAAK,YAAS,CAAC,sBAAsB,EAAE;QAClD,IAAI,QAAQ,IAAI,IAAI,EAAE;YACpB,OAAO,gLAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,YAAY,CAAC,+KAAE,SAAA,AAAM,EAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC;SACrD,MAAM;YACL,MAAM,kBAAkB,6KAAG,MAAA,AAAG,EAAC,QAAQ,EAAE,kLAAA,AAAI,EAAC,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC;YAE9D,MAAM,WAAW,8KACb,OAAA,AAAI,GAAC,+KAAA,AAAG,kLAAC,WAAA,AAAQ,EAAC,kBAAkB,GAAE,qLAAA,AAAM,EAAC,CAAC,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;YAClE,iLAAO,MAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,YAAY,CAAC,EAAE,WAAW,CAAC,CAAC;SAC5C;KACF;IAED,MAAM,KAAK,CAAC,CAAA,mBAAA,EAAsB,SAAS,EAAE,CAAC,CAAC;AACjD,CAAC;AACM,MAAM,mBAAmB,GAAG,aAAA,EAAe,iLAAC,KAAA,AAAE,EAAC;IAAC,oBAAoB;AAAA,CAAC,CAAC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 84, "column": 0}, "map": {"version":3,"file":"absolute_difference.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js/__/__/__/__/__/__/__/tfjs-core/src/ops/losses/absolute_difference.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {abs} from '../abs';\nimport {Reduction} from '../loss_ops_utils';\nimport {op} from '../operation';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the absolute difference loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction absoluteDifference_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'absoluteDifference');\n  const $predictions =\n      convertToTensor(predictions, 'predictions', 'absoluteDifference');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'absoluteDifference');\n  }\n  assertShapesMatch(\n      $labels.shape, $predictions.shape, 'Error in absoluteDifference: ');\n\n  const losses = abs(sub($labels, $predictions));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\n\nexport const absoluteDifference = /* @__PURE__ */ op({absoluteDifference_});\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;;;AAGH,OAAO,EAAC,eAAe,EAAC,MAAM,uBAAuB,CAAC;AAEtD,OAAO,EAAC,iBAAiB,EAAC,MAAM,YAAY,CAAC;AAC7C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAC5C,OAAO,EAAC,EAAE,EAAC,MAAM,cAAc,CAAC;AAChC,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAE3B,OAAO,EAAC,mBAAmB,EAAC,MAAM,yBAAyB,CAAC;;;;;;;;AAE5D;;;;;;;;;;;;;;GAcG,CACH,SAAS,mBAAmB,CACxB,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAC3B,SAAS,GAAG,6LAAS,CAAC,sBAAsB;IAC9C,MAAM,OAAO,kLAAG,kBAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,oBAAoB,CAAC,CAAC;IACxE,MAAM,YAAY,kLACd,kBAAA,AAAe,EAAC,WAAW,EAAE,aAAa,EAAE,oBAAoB,CAAC,CAAC;IACtE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,kLAAG,kBAAA,AAAe,EAAC,OAAO,EAAE,SAAS,EAAE,oBAAoB,CAAC,CAAC;KACtE;KACD,4LAAA,AAAiB,EACb,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,+BAA+B,CAAC,CAAC;IAExE,MAAM,MAAM,6KAAG,MAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,OAAO,EAAE,YAAY,CAAC,CAAC,CAAC;IAC/C,6MAAO,sBAAA,AAAmB,EAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAEM,MAAM,kBAAkB,GAAG,aAAA,EAAe,iLAAC,KAAA,AAAE,EAAC;IAAC,mBAAmB;AAAA,CAAC,CAAC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 150, "column": 0}, "map": {"version":3,"file":"cosine_distance.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-core/dist/ops/losses/cosine_distance.js/__/__/__/__/__/__/__/tfjs-core/src/ops/losses/cosine_distance.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\nimport {sum} from '../sum';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the cosine distance loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param axis The dimension along which the cosine distance is computed.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction cosineDistance_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike, axis: number,\n    weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'cosineDistance');\n  const $predictions =\n      convertToTensor(predictions, 'predictions', 'cosineDistance');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'cosineDistance');\n  }\n  assertShapesMatch(\n      $labels.shape, $predictions.shape, 'Error in cosineDistance: ');\n\n  const one = scalar(1);\n  const losses = sub(one, sum(mul($labels, $predictions), axis, true));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const cosineDistance = /* @__PURE__ */ op({cosineDistance_});\n"],"names":[],"mappings":";;;AAiBA,OAAO,EAAC,eAAe,EAAC,MAAM,uBAAuB,CAAC;AAEtD,OAAO,EAAC,iBAAiB,EAAC,MAAM,YAAY,CAAC;AAC7C,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAC5C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,EAAE,EAAC,MAAM,cAAc,CAAC;AAChC,OAAO,EAAC,MAAM,EAAC,MAAM,WAAW,CAAC;AACjC,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAE3B,OAAO,EAAC,mBAAmB,EAAC,MAAM,yBAAyB,CAAC;;;;;;;;;;AAE5D;;;;;;;;;;;;;;;GAeG,CACH,SAAS,eAAe,CACpB,MAAoB,EAAE,WAAyB,EAAE,IAAY,EAC7D,OAA2B,EAC3B,SAAS,oLAAG,YAAS,CAAC,sBAAsB;IAC9C,MAAM,OAAO,kLAAG,kBAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,gBAAgB,CAAC,CAAC;IACpE,MAAM,YAAY,IACd,gMAAA,AAAe,EAAC,WAAW,EAAE,aAAa,EAAE,gBAAgB,CAAC,CAAC;IAClE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,IAAG,gMAAA,AAAe,EAAC,OAAO,EAAE,SAAS,EAAE,gBAAgB,CAAC,CAAC;KAClE;6KACD,oBAAA,AAAiB,EACb,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,2BAA2B,CAAC,CAAC;IAEpE,MAAM,GAAG,gLAAG,SAAA,AAAM,EAAC,CAAC,CAAC,CAAC;IACtB,MAAM,MAAM,GAAG,gLAAA,AAAG,EAAC,GAAG,4KAAE,MAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,OAAO,EAAE,YAAY,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC;IACrE,6MAAO,sBAAA,AAAmB,EAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AACM,MAAM,cAAc,GAAG,aAAA,EAAe,iLAAC,KAAA,AAAE,EAAC;IAAC,eAAe;AAAA,CAAC,CAAC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 207, "column": 0}, "map": {"version":3,"file":"hinge_loss.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-core/dist/ops/losses/hinge_loss.js/__/__/__/__/__/__/__/tfjs-core/src/ops/losses/hinge_loss.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {op} from '../operation';\nimport {relu} from '../relu';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the Hinge loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction hingeLoss_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  let $labels = convertToTensor(labels, 'labels', 'hingeLoss');\n  const $predictions = convertToTensor(predictions, 'predictions', 'hingeLoss');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'hingeLoss');\n  }\n  assertShapesMatch($labels.shape, $predictions.shape, 'Error in hingeLoss: ');\n\n  const one = scalar(1);\n  // Convert binary labels to (-1, 1)\n  $labels = sub(mul(scalar(2), $labels), one);\n  const losses = relu(sub(one, mul($labels, $predictions)));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const hingeLoss = /* @__PURE__ */ op({hingeLoss_});\n"],"names":[],"mappings":";;;AAiBA,OAAO,EAAC,eAAe,EAAC,MAAM,uBAAuB,CAAC;AAEtD,OAAO,EAAC,iBAAiB,EAAC,MAAM,YAAY,CAAC;AAC7C,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAC5C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,EAAE,EAAC,MAAM,cAAc,CAAC;AAChC,OAAO,EAAC,IAAI,EAAC,MAAM,SAAS,CAAC;AAC7B,OAAO,EAAC,MAAM,EAAC,MAAM,WAAW,CAAC;AACjC,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAE3B,OAAO,EAAC,mBAAmB,EAAC,MAAM,yBAAyB,CAAC;;;;;;;;;;AAE5D;;;;;;;;;;;;;;GAcG,CACH,SAAS,UAAU,CACf,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAC3B,SAAS,oLAAG,YAAS,CAAC,sBAAsB;IAC9C,IAAI,OAAO,GAAG,iMAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,WAAW,CAAC,CAAC;IAC7D,MAAM,YAAY,kLAAG,kBAAA,AAAe,EAAC,WAAW,EAAE,aAAa,EAAE,WAAW,CAAC,CAAC;IAC9E,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,kLAAG,kBAAA,AAAe,EAAC,OAAO,EAAE,SAAS,EAAE,WAAW,CAAC,CAAC;KAC7D;KACD,4LAAA,AAAiB,EAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,sBAAsB,CAAC,CAAC;IAE7E,MAAM,GAAG,gLAAG,SAAA,AAAM,EAAC,CAAC,CAAC,CAAC;IACtB,mCAAmC;IACnC,OAAO,6KAAG,MAAA,AAAG,4KAAC,MAAA,AAAG,GAAC,qLAAA,AAAM,EAAC,CAAC,CAAC,EAAE,OAAO,CAAC,EAAE,GAAG,CAAC,CAAC;IAC5C,MAAM,MAAM,8KAAG,OAAA,AAAI,4KAAC,MAAA,AAAG,EAAC,GAAG,GAAE,+KAAA,AAAG,EAAC,OAAO,EAAE,YAAY,CAAC,CAAC,CAAC,CAAC;IAC1D,6MAAO,sBAAA,AAAmB,EAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AACM,MAAM,SAAS,GAAG,aAAA,EAAe,iLAAC,KAAA,AAAE,EAAC;IAAC,UAAU;AAAA,CAAC,CAAC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 265, "column": 0}, "map": {"version":3,"file":"huber_loss.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-core/dist/ops/losses/huber_loss.js/__/__/__/__/__/__/__/tfjs-core/src/ops/losses/huber_loss.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {abs} from '../abs';\nimport {add} from '../add';\nimport {Reduction} from '../loss_ops_utils';\nimport {minimum} from '../minimum';\nimport {mul} from '../mul';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {square} from '../square';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the Huber loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param delta Point where Huber loss changes from quadratic to linear.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`.\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction huberLoss_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike, delta = 1.0,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'huberLoss');\n  const $predictions = convertToTensor(predictions, 'predictions', 'huberLoss');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'huberLoss');\n  }\n  assertShapesMatch($labels.shape, $predictions.shape, 'Error in huberLoss: ');\n\n  const deltaScalar = scalar(delta);\n  const error = abs(sub($predictions, $labels));\n  const quadratic = minimum(error, deltaScalar);\n  const linear = sub(error, quadratic);\n\n  const losses =\n      add(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const huberLoss = /* @__PURE__ */ op({huberLoss_});\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;;;AAGH,OAAO,EAAC,eAAe,EAAC,MAAM,uBAAuB,CAAC;AAEtD,OAAO,EAAC,iBAAiB,EAAC,MAAM,YAAY,CAAC;AAC7C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAC5C,OAAO,EAAC,OAAO,EAAC,MAAM,YAAY,CAAC;AACnC,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,EAAE,EAAC,MAAM,cAAc,CAAC;AAChC,OAAO,EAAC,MAAM,EAAC,MAAM,WAAW,CAAC;AACjC,OAAO,EAAC,MAAM,EAAC,MAAM,WAAW,CAAC;AACjC,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAE3B,OAAO,EAAC,mBAAmB,EAAC,MAAM,yBAAyB,CAAC;;;;;;;;;;;;;AAE5D;;;;;;;;;;;;;;;GAeG,CACH,SAAS,UAAU,CACf,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAAE,KAAK,GAAG,GAAG,EACxC,SAAS,GAAG,6LAAS,CAAC,sBAAsB;IAC9C,MAAM,OAAO,kLAAG,kBAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,WAAW,CAAC,CAAC;IAC/D,MAAM,YAAY,kLAAG,kBAAA,AAAe,EAAC,WAAW,EAAE,aAAa,EAAE,WAAW,CAAC,CAAC;IAC9E,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,kLAAG,kBAAA,AAAe,EAAC,OAAO,EAAE,SAAS,EAAE,WAAW,CAAC,CAAC;KAC7D;6KACD,oBAAA,AAAiB,EAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,sBAAsB,CAAC,CAAC;IAE7E,MAAM,WAAW,gLAAG,SAAA,AAAM,EAAC,KAAK,CAAC,CAAC;IAClC,MAAM,KAAK,6KAAG,MAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,YAAY,EAAE,OAAO,CAAC,CAAC,CAAC;IAC9C,MAAM,SAAS,iLAAG,UAAA,AAAO,EAAC,KAAK,EAAE,WAAW,CAAC,CAAC;IAC9C,MAAM,MAAM,6KAAG,MAAA,AAAG,EAAC,KAAK,EAAE,SAAS,CAAC,CAAC;IAErC,MAAM,MAAM,6KACR,MAAA,AAAG,4KAAC,MAAA,AAAG,+KAAC,SAAA,AAAM,EAAC,GAAG,CAAC,EAAE,sLAAA,AAAM,EAAC,SAAS,CAAC,CAAC,4KAAE,MAAA,AAAG,EAAC,WAAW,EAAE,MAAM,CAAC,CAAC,CAAC;IACvE,6MAAO,sBAAA,AAAmB,EAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AACM,MAAM,SAAS,GAAG,aAAA,EAAe,iLAAC,KAAA,AAAE,EAAC;IAAC,UAAU;AAAA,CAAC,CAAC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 346, "column": 0}, "map": {"version":3,"file":"log_loss.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-core/dist/ops/losses/log_loss.js/__/__/__/__/__/__/__/tfjs-core/src/ops/losses/log_loss.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {add} from '../add';\nimport {log} from '../log';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {neg} from '../neg';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the log loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param epsilon A small increment to avoid taking log of zero\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction logLoss_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike, epsilon = 1e-7,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'logLoss');\n  const $predictions = convertToTensor(predictions, 'predictions', 'logLoss');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'logLoss');\n  }\n  assertShapesMatch($labels.shape, $predictions.shape, 'Error in logLoss: ');\n\n  const one = scalar(1);\n  const epsilonScalar = scalar(epsilon);\n\n  const l1 = neg(mul($labels, log(add($predictions, epsilonScalar))));\n  const l2 =\n      mul(sub(one, $labels), log(add(sub(one, $predictions), epsilonScalar)));\n  const losses = sub(l1, l2);\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const logLoss = /* @__PURE__ */ op({logLoss_});\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;;;AAGH,OAAO,EAAC,eAAe,EAAC,MAAM,uBAAuB,CAAC;AAEtD,OAAO,EAAC,iBAAiB,EAAC,MAAM,YAAY,CAAC;AAC7C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAC5C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,EAAE,EAAC,MAAM,cAAc,CAAC;AAChC,OAAO,EAAC,MAAM,EAAC,MAAM,WAAW,CAAC;AACjC,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAE3B,OAAO,EAAC,mBAAmB,EAAC,MAAM,yBAAyB,CAAC;;;;;;;;;;;;AAE5D;;;;;;;;;;;;;;;GAeG,CACH,SAAS,QAAQ,CACb,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAAE,OAAO,GAAG,IAAI,EAC3C,SAAS,oLAAG,YAAS,CAAC,sBAAsB;IAC9C,MAAM,OAAO,OAAG,6LAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;IAC7D,MAAM,YAAY,kLAAG,kBAAA,AAAe,EAAC,WAAW,EAAE,aAAa,EAAE,SAAS,CAAC,CAAC;IAC5E,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,IAAG,gMAAA,AAAe,EAAC,OAAO,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC;KAC3D;6KACD,oBAAA,AAAiB,EAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,oBAAoB,CAAC,CAAC;IAE3E,MAAM,GAAG,IAAG,qLAAA,AAAM,EAAC,CAAC,CAAC,CAAC;IACtB,MAAM,aAAa,gLAAG,SAAA,AAAM,EAAC,OAAO,CAAC,CAAC;IAEtC,MAAM,EAAE,6KAAG,MAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,OAAO,EAAE,gLAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,YAAY,EAAE,aAAa,CAAC,CAAC,CAAC,CAAC,CAAC;IACpE,MAAM,EAAE,6KACJ,MAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,GAAG,EAAE,OAAO,CAAC,4KAAE,MAAA,AAAG,4KAAC,MAAA,AAAG,GAAC,+KAAA,AAAG,EAAC,GAAG,EAAE,YAAY,CAAC,EAAE,aAAa,CAAC,CAAC,CAAC,CAAC;IAC5E,MAAM,MAAM,6KAAG,MAAA,AAAG,EAAC,EAAE,EAAE,EAAE,CAAC,CAAC;IAC3B,6MAAO,sBAAA,AAAmB,EAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AACM,MAAM,OAAO,GAAG,aAAA,EAAe,iLAAC,KAAA,AAAE,EAAC;IAAC,QAAQ;AAAA,CAAC,CAAC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 425, "column": 0}, "map": {"version":3,"file":"mean_squared_error.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js/__/__/__/__/__/__/__/tfjs-core/src/ops/losses/mean_squared_error.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {Reduction} from '../loss_ops_utils';\nimport {op} from '../operation';\nimport {squaredDifference} from '../squared_difference';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the mean squared error between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction meanSquaredError_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike,\n    weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'meanSquaredError');\n  const $predictions =\n      convertToTensor(predictions, 'predictions', 'meanSquaredError');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'meanSquaredError');\n  }\n  assertShapesMatch(\n      $labels.shape, $predictions.shape, 'Error in meanSquaredError: ');\n\n  const losses = squaredDifference($labels, $predictions);\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const meanSquaredError = /* @__PURE__ */ op({meanSquaredError_});\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;;;AAGH,OAAO,EAAC,eAAe,EAAC,MAAM,uBAAuB,CAAC;AAEtD,OAAO,EAAC,iBAAiB,EAAC,MAAM,YAAY,CAAC;AAC7C,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAC5C,OAAO,EAAC,EAAE,EAAC,MAAM,cAAc,CAAC;AAChC,OAAO,EAAC,iBAAiB,EAAC,MAAM,uBAAuB,CAAC;AAExD,OAAO,EAAC,mBAAmB,EAAC,MAAM,yBAAyB,CAAC;;;;;;;AAE5D;;;;;;;;;;;;;;GAcG,CACH,SAAS,iBAAiB,CACtB,MAAoB,EAAE,WAAyB,EAC/C,OAA2B,EAC3B,SAAS,mLAAG,aAAS,CAAC,sBAAsB;IAC9C,MAAM,OAAO,kLAAG,kBAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,kBAAkB,CAAC,CAAC;IACtE,MAAM,YAAY,kLACd,kBAAA,AAAe,EAAC,WAAW,EAAE,aAAa,EAAE,kBAAkB,CAAC,CAAC;IACpE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,kLAAG,kBAAA,AAAe,EAAC,OAAO,EAAE,SAAS,EAAE,kBAAkB,CAAC,CAAC;KACpE;6KACD,oBAAA,AAAiB,EACb,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,EAAE,6BAA6B,CAAC,CAAC;IAEtE,MAAM,MAAM,4LAAG,oBAAA,AAAiB,EAAC,OAAO,EAAE,YAAY,CAAC,CAAC;IACxD,6MAAO,sBAAA,AAAmB,EAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AACM,MAAM,gBAAgB,GAAG,aAAA,EAAe,iLAAC,KAAA,AAAE,EAAC;IAAC,iBAAiB;AAAA,CAAC,CAAC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 489, "column": 0}, "map": {"version":3,"file":"sigmoid_cross_entropy.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js/__/__/__/__/__/__/__/tfjs-core/src/ops/losses/sigmoid_cross_entropy.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {abs} from '../abs';\nimport {add} from '../add';\nimport {exp} from '../exp';\nimport {log1p} from '../log1p';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {neg} from '../neg';\nimport {op} from '../operation';\nimport {relu} from '../relu';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\nfunction sigmoidCrossEntropyWithLogits_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, logits: T|TensorLike): O {\n  const $labels =\n      convertToTensor(labels, 'labels', 'sigmoidCrossEntropyWithLogits');\n  const $logits =\n      convertToTensor(logits, 'logits', 'sigmoidCrossEntropyWithLogits');\n  assertShapesMatch(\n      $labels.shape, $logits.shape, 'Error in sigmoidCrossEntropyWithLogits: ');\n\n  /**\n   * Implementation Details:\n   *\n   * For brevity, let `x = logits`, `z = labels`.  The logistic loss is\n   *     z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n   *   = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n   *   = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n   *   = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n   *   = (1 - z) * x + log(1 + exp(-x))\n   *   = x - x * z + log(1 + exp(-x))\n   *\n   *   For x < 0, to avoid overflow in exp(-x), we reformulate the above\n   *     x - x * z + log(1 + exp(-x))\n   *   = log(exp(x)) - x * z + log(1 + exp(-x))\n   *   = - x * z + log(1 + exp(x))\n   *\n   * Hence, to ensure stability and avoid overflow, the implementation uses\n   * this equivalent formulation:\n   *     max(x, 0) - x * z + log(1 + exp(-abs(x)))\n   */\n  const maxOutput = relu($logits);\n  const outputXTarget = mul($logits, $labels);\n  const sigmoidOutput = log1p(exp(neg(abs($logits))));\n\n  return add(sub(maxOutput, outputXTarget), sigmoidOutput);\n}\n\n/**\n * Computes the sigmoid cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newMulticlassLabels = multiclassLabels * (1 - labelSmoothing)\n *                         + 0.5 * labelSmoothing\n *\n * @param multiClassLabels The ground truth output tensor of shape\n * [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' }\n */\nfunction sigmoidCrossEntropy_<T extends Tensor, O extends Tensor>(\n    multiClassLabels: T|TensorLike, logits: T|TensorLike,\n    weights?: Tensor|TensorLike, labelSmoothing = 0,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  let $multiClassLabels = convertToTensor(\n      multiClassLabels, 'multiClassLabels', 'sigmoidCrossEntropy');\n  const $logits = convertToTensor(logits, 'logits', 'sigmoidCrossEntropy');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'sigmoidCrossEntropy');\n  }\n  assertShapesMatch(\n      $multiClassLabels.shape, $logits.shape, 'Error in sigmoidCrossEntropy: ');\n\n  if (labelSmoothing > 0) {\n    const labelSmoothingScalar = scalar(labelSmoothing);\n    const one = scalar(1);\n    const half = scalar(0.5);\n\n    $multiClassLabels =\n        add(mul($multiClassLabels, sub(one, labelSmoothingScalar)),\n            mul(half, labelSmoothingScalar));\n  }\n  const losses = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);\n\n  return computeWeightedLoss(losses, $weights, reduction);\n}\n\nexport const sigmoidCrossEntropy = /* @__PURE__ */ op({sigmoidCrossEntropy_});\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;;;AAGH,OAAO,EAAC,eAAe,EAAC,MAAM,uBAAuB,CAAC;AAEtD,OAAO,EAAC,iBAAiB,EAAC,MAAM,YAAY,CAAC;AAC7C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,KAAK,EAAC,MAAM,UAAU,CAAC;AAC/B,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAC5C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,EAAE,EAAC,MAAM,cAAc,CAAC;AAChC,OAAO,EAAC,IAAI,EAAC,MAAM,SAAS,CAAC;AAC7B,OAAO,EAAC,MAAM,EAAC,MAAM,WAAW,CAAC;AACjC,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAE3B,OAAO,EAAC,mBAAmB,EAAC,MAAM,yBAAyB,CAAC;;;;;;;;;;;;;;;AAE5D,SAAS,8BAA8B,CACnC,MAAoB,EAAE,MAAoB;IAC5C,MAAM,OAAO,OACT,6LAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,+BAA+B,CAAC,CAAC;IACvE,MAAM,OAAO,kLACT,kBAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,+BAA+B,CAAC,CAAC;QACvE,yLAAA,AAAiB,EACb,OAAO,CAAC,KAAK,EAAE,OAAO,CAAC,KAAK,EAAE,0CAA0C,CAAC,CAAC;IAE9E;;;;;;;;;;;;;;;;;;;OAmBG,CACH,MAAM,SAAS,8KAAG,OAAA,AAAI,EAAC,OAAO,CAAC,CAAC;IAChC,MAAM,aAAa,6KAAG,MAAA,AAAG,EAAC,OAAO,EAAE,OAAO,CAAC,CAAC;IAC5C,MAAM,aAAa,+KAAG,QAAA,AAAK,EAAC,gLAAA,AAAG,4KAAC,MAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;IAEpD,WAAO,4KAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,SAAS,EAAE,aAAa,CAAC,EAAE,aAAa,CAAC,CAAC;AAC3D,CAAC;AAED;;;;;;;;;;;;;;;;;;;;GAoBG,CACH,SAAS,oBAAoB,CACzB,gBAA8B,EAAE,MAAoB,EACpD,OAA2B,EAAE,cAAc,GAAG,CAAC,EAC/C,SAAS,oLAAG,YAAS,CAAC,sBAAsB;IAC9C,IAAI,iBAAiB,GAAG,iMAAA,AAAe,EACnC,gBAAgB,EAAE,kBAAkB,EAAE,qBAAqB,CAAC,CAAC;IACjE,MAAM,OAAO,kLAAG,kBAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,qBAAqB,CAAC,CAAC;IACzE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAC5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,kLAAG,kBAAA,AAAe,EAAC,OAAO,EAAE,SAAS,EAAE,qBAAqB,CAAC,CAAC;KACvE;QACD,yLAAA,AAAiB,EACb,iBAAiB,CAAC,KAAK,EAAE,OAAO,CAAC,KAAK,EAAE,gCAAgC,CAAC,CAAC;IAE9E,IAAI,cAAc,GAAG,CAAC,EAAE;QACtB,MAAM,oBAAoB,GAAG,sLAAA,AAAM,EAAC,cAAc,CAAC,CAAC;QACpD,MAAM,GAAG,gLAAG,SAAA,AAAM,EAAC,CAAC,CAAC,CAAC;QACtB,MAAM,IAAI,gLAAG,SAAA,AAAM,EAAC,GAAG,CAAC,CAAC;QAEzB,iBAAiB,6KACb,MAAA,AAAG,EAAC,gLAAA,AAAG,EAAC,iBAAiB,4KAAE,MAAA,AAAG,EAAC,GAAG,EAAE,oBAAoB,CAAC,CAAC,4KACtD,MAAA,AAAG,EAAC,IAAI,EAAE,oBAAoB,CAAC,CAAC,CAAC;KAC1C;IACD,MAAM,MAAM,GAAG,8BAA8B,CAAC,iBAAiB,EAAE,OAAO,CAAC,CAAC;IAE1E,6MAAO,sBAAA,AAAmB,EAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAEM,MAAM,mBAAmB,GAAG,aAAA,EAAe,iLAAC,KAAA,AAAE,EAAC;IAAC,oBAAoB;AAAA,CAAC,CAAC,CAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 609, "column": 0}, "map": {"version":3,"file":"softmax_cross_entropy.js","sourceRoot":"","sources":["file:///project/sandbox/user-workspace/node_modules/%40tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js/__/__/__/__/__/__/__/tfjs-core/src/ops/losses/softmax_cross_entropy.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {customGrad} from '../../gradients';\nimport {Tensor} from '../../tensor';\nimport {GradSaveFunc} from '../../tensor_types';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {add} from '../add';\nimport {expandShapeToKeepDim} from '../axis_util';\nimport {cast} from '../cast';\nimport {div} from '../div';\nimport {exp} from '../exp';\nimport {logSumExp} from '../log_sum_exp';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {neg} from '../neg';\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\nimport {sum} from '../sum';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes softmax cross entropy between logits and labels.\n *\n * Measures the probability error in discrete classification tasks in which\n * the classes are mutually exclusive (each entry is in exactly one class).\n * For example, each CIFAR-10 image is labeled with one and only one label: an\n * image can be a dog or a truck, but not both.\n *\n * `NOTE`: While the classes are mutually exclusive, their probabilities need\n * not be. All that is required is that each row of labels is a valid\n * probability distribution. If they are not, the computation of the gradient\n * will be incorrect.\n *\n * `WARNING`: This op expects unscaled logits, since it performs a softmax on\n * logits internally for efficiency. Do not call this op with the output of\n * softmax, as it will produce incorrect results.\n *\n * logits and labels must have the same shape, e.g. [batch_size, num_classes]\n * and the same dtype.\n * @param labels The labels array.\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n */\nfunction softmaxCrossEntropyWithLogits_<T extends Tensor, O extends Tensor>(\n    labels: T, logits: T, dim = -1): O {\n  if (dim === -1) {\n    dim = logits.rank - 1;\n  }\n\n  if (dim !== logits.rank - 1) {\n    throw Error(\n        `Softmax cross entropy along a non-last dimension is not yet ` +\n        `supported. Labels / logits was rank ${logits.rank} ` +\n        `and dim was ${dim}`);\n  }\n  // Use a custom gradient for numerical stability.\n  const customOp =\n      customGrad((labels: Tensor, logits: Tensor, save: GradSaveFunc) => {\n        // Reference:\n        //   1. http://cs231n.github.io/linear-classify/#softmax\n        //   2. https://blog.feedly.com/tricks-of-the-trade-logsumexp/\n        const keepDims = true;\n        const lse = logSumExp(logits, [dim], keepDims);\n        const logResult = sub(cast(logits, 'float32'), lse);\n        save([labels, logResult]);\n\n        const costVector = neg(mul(logResult, labels));\n        const value: O = sum(costVector, [dim]);\n\n        const gradFunc = (dy: O, saved: Tensor[]) => {\n          const [labels, logResult] = saved;\n          const dyShape = expandShapeToKeepDim(dy.shape, [dim]);\n          return [\n            mul(reshape(dy, dyShape),\n                sub(cast(labels, 'float32'), exp(logResult))),\n            mul(reshape(dy, dyShape),\n                sub(exp(logResult), cast(labels, 'float32'))),\n          ];\n        };\n        return {value, gradFunc};\n      });\n\n  return customOp(labels, logits);\n}\n\n/**\n * Computes the softmax cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newOnehotLabels = onehotLabels * (1 - labelSmoothing)\n *                         + labelSmoothing / numClasses\n *\n * @param onehotLabels One hot encoded labels\n *    [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or 1, and must be\n *    broadcastable to `loss`  of shape [batch_size]\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' }\n */\nfunction softmaxCrossEntropy_<T extends Tensor, O extends Tensor>(\n    onehotLabels: T|TensorLike, logits: T|TensorLike,\n    weights?: Tensor|TensorLike, labelSmoothing = 0,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  let $onehotLabels =\n      convertToTensor(onehotLabels, 'onehotLabels', 'softmaxCrossEntropy');\n  const $logits = convertToTensor(logits, 'logits', 'softmaxCrossEntropy');\n  let $weights: Tensor = null;\n\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'softmaxCrossEntropy');\n  }\n\n  assertShapesMatch(\n      $onehotLabels.shape, $logits.shape, 'Error in softmaxCrossEntropy: ');\n\n  if (labelSmoothing > 0) {\n    const labelSmoothingScalar = scalar(labelSmoothing);\n    const one = scalar(1);\n    const numClasses = scalar($onehotLabels.shape[1]);\n\n    $onehotLabels =\n        add(mul($onehotLabels, sub(one, labelSmoothingScalar)),\n            div(labelSmoothingScalar, numClasses));\n  }\n\n  const losses = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);\n\n  return computeWeightedLoss(losses, $weights, reduction);\n}\n\nexport const softmaxCrossEntropy = /* @__PURE__ */ op({softmaxCrossEntropy_});\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;;;AACH,OAAO,EAAC,UAAU,EAAC,MAAM,iBAAiB,CAAC;AAG3C,OAAO,EAAC,eAAe,EAAC,MAAM,uBAAuB,CAAC;AAEtD,OAAO,EAAC,iBAAiB,EAAC,MAAM,YAAY,CAAC;AAC7C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,oBAAoB,EAAC,MAAM,cAAc,CAAC;AAClD,OAAO,EAAC,IAAI,EAAC,MAAM,SAAS,CAAC;AAC7B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,SAAS,EAAC,MAAM,gBAAgB,CAAC;AACzC,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAC5C,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,EAAE,EAAC,MAAM,cAAc,CAAC;AAChC,OAAO,EAAC,OAAO,EAAC,MAAM,YAAY,CAAC;AACnC,OAAO,EAAC,MAAM,EAAC,MAAM,WAAW,CAAC;AACjC,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAE3B,OAAO,EAAC,mBAAmB,EAAC,MAAM,yBAAyB,CAAC;;;;;;;;;;;;;;;;;;;AAE5D;;;;;;;;;;;;;;;;;;;;;;;GAuBG,CACH,SAAS,8BAA8B,CACnC,MAAS,EAAE,MAAS,EAAE,GAAG,GAAG,CAAC,CAAC;IAChC,IAAI,GAAG,KAAK,CAAC,CAAC,EAAE;QACd,GAAG,GAAG,MAAM,CAAC,IAAI,GAAG,CAAC,CAAC;KACvB;IAED,IAAI,GAAG,KAAK,MAAM,CAAC,IAAI,GAAG,CAAC,EAAE;QAC3B,MAAM,KAAK,CACP,CAAA,4DAAA,CAA8D,GAC9D,CAAA,oCAAA,EAAuC,MAAM,CAAC,IAAI,CAAA,CAAA,CAAG,GACrD,CAAA,YAAA,EAAe,GAAG,EAAE,CAAC,CAAC;KAC3B;IACD,iDAAiD;IACjD,MAAM,QAAQ,OACV,kLAAA,AAAU,EAAC,CAAC,MAAc,EAAE,MAAc,EAAE,IAAkB,EAAE,EAAE;QAChE,aAAa;QACb,wDAAwD;QACxD,8DAA8D;QAC9D,MAAM,QAAQ,GAAG,IAAI,CAAC;QACtB,MAAM,GAAG,IAAG,6LAAA,AAAS,EAAC,MAAM,EAAE;YAAC,GAAG;SAAC,EAAE,QAAQ,CAAC,CAAC;QAC/C,MAAM,SAAS,OAAG,4KAAA,AAAG,6KAAC,OAAA,AAAI,EAAC,MAAM,EAAE,SAAS,CAAC,EAAE,GAAG,CAAC,CAAC;QACpD,IAAI,CAAC;YAAC,MAAM;YAAE,SAAS;SAAC,CAAC,CAAC;QAE1B,MAAM,UAAU,6KAAG,MAAA,AAAG,GAAC,+KAAA,AAAG,EAAC,SAAS,EAAE,MAAM,CAAC,CAAC,CAAC;QAC/C,MAAM,KAAK,6KAAM,MAAA,AAAG,EAAC,UAAU,EAAE;YAAC,GAAG;SAAC,CAAC,CAAC;QAExC,MAAM,QAAQ,GAAG,CAAC,EAAK,EAAE,KAAe,EAAE,EAAE;YAC1C,MAAM,CAAC,MAAM,EAAE,SAAS,CAAC,GAAG,KAAK,CAAC;YAClC,MAAM,OAAO,mLAAG,uBAAA,AAAoB,EAAC,EAAE,CAAC,KAAK,EAAE;gBAAC,GAAG;aAAC,CAAC,CAAC;YACtD,OAAO;0LACL,MAAA,AAAG,gLAAC,UAAA,AAAO,EAAC,EAAE,EAAE,OAAO,CAAC,4KACpB,MAAA,AAAG,6KAAC,OAAA,AAAI,EAAC,MAAM,EAAE,SAAS,CAAC,4KAAE,MAAA,AAAG,EAAC,SAAS,CAAC,CAAC,CAAC;gBACjD,gLAAA,AAAG,gLAAC,UAAA,AAAO,EAAC,EAAE,EAAE,OAAO,CAAC,4KACpB,MAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,SAAS,CAAC,EAAE,kLAAA,AAAI,EAAC,MAAM,EAAE,SAAS,CAAC,CAAC,CAAC;aAClD,CAAC;QACJ,CAAC,CAAC;QACF,OAAO;YAAC,KAAK;YAAE,QAAQ;QAAA,CAAC,CAAC;IAC3B,CAAC,CAAC,CAAC;IAEP,OAAO,QAAQ,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;AAClC,CAAC;AAED;;;;;;;;;;;;;;;;;;GAkBG,CACH,SAAS,oBAAoB,CACzB,YAA0B,EAAE,MAAoB,EAChD,OAA2B,EAAE,cAAc,GAAG,CAAC,EAC/C,SAAS,oLAAG,YAAS,CAAC,sBAAsB;IAC9C,IAAI,aAAa,kLACb,kBAAA,AAAe,EAAC,YAAY,EAAE,cAAc,EAAE,qBAAqB,CAAC,CAAC;IACzE,MAAM,OAAO,IAAG,gMAAA,AAAe,EAAC,MAAM,EAAE,QAAQ,EAAE,qBAAqB,CAAC,CAAC;IACzE,IAAI,QAAQ,GAAW,IAAI,CAAC;IAE5B,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,QAAQ,kLAAG,kBAAA,AAAe,EAAC,OAAO,EAAE,SAAS,EAAE,qBAAqB,CAAC,CAAC;KACvE;6KAED,oBAAA,AAAiB,EACb,aAAa,CAAC,KAAK,EAAE,OAAO,CAAC,KAAK,EAAE,gCAAgC,CAAC,CAAC;IAE1E,IAAI,cAAc,GAAG,CAAC,EAAE;QACtB,MAAM,oBAAoB,gLAAG,SAAA,AAAM,EAAC,cAAc,CAAC,CAAC;QACpD,MAAM,GAAG,gLAAG,SAAA,AAAM,EAAC,CAAC,CAAC,CAAC;QACtB,MAAM,UAAU,gLAAG,SAAA,AAAM,EAAC,aAAa,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QAElD,aAAa,6KACT,MAAA,AAAG,4KAAC,MAAA,AAAG,EAAC,aAAa,4KAAE,MAAA,AAAG,EAAC,GAAG,EAAE,oBAAoB,CAAC,CAAC,4KAClD,MAAA,AAAG,EAAC,oBAAoB,EAAE,UAAU,CAAC,CAAC,CAAC;KAChD;IAED,MAAM,MAAM,GAAG,8BAA8B,CAAC,aAAa,EAAE,OAAO,CAAC,CAAC;IAEtE,6MAAO,sBAAA,AAAmB,EAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;AAC1D,CAAC;AAEM,MAAM,mBAAmB,GAAG,aAAA,EAAe,iLAAC,KAAA,AAAE,EAAC;IAAC,oBAAoB;AAAA,CAAC,CAAC,CAAC","ignoreList":[0],"debugId":null}}]
}